# ğŸ“Š Sparklyr en mode cluster

## Adapter la configuration

Pour effectuer des traitements avec Sparklyr en mode cluster, il n'y a pas beaucoup de diffÃ©rences avec les traitements en mode local :

```r
library(sparklyr)
library(dplyr)

# InsÃ©rer ici vos configurations personelles pour votre session
conf <- spark_config() 
conf["spark.driver.memory"] <- "16g"
conf["spark.executor.memory"] <- "8g"
conf["spark.executor.core"] <- 4
conf["spark.executor.instances"] <- 2
conf["spark.yarn.queue"] <- "prod"

# CrÃ©ation de la connexion Sparklyr en mode cluster
sc <- spark_connect(master = "yarn", config = conf)
```

Notez la prÃ©sence du paramÃ¨tre spark.yarn.queue. Il n'existe pas de file par dÃ©faut pour forcer le choix vers une des files adaptÃ©es. Ne pas prÃ©ciser ce paramÃ¨tre amÃ¨nera le traitement Ã  Ã©chouer !

Une fois cette configuration effectuÃ©e, il faut effectuer vos traitements comme vous le feriez en mode local.

Attention Ã  l'instruction collect : elle ramÃ¨ne le dataset vers la machine depuis laquelle vous accÃ©dez votre session R ! Si le dataset est de taille trÃ¨s importante, cela peut causer une erreur mÃ©moire, car R chargera ce dataset dans la mÃ©moire de la machine et non sur disque. Cette instruction n'est Ã  rÃ©server qu'aux rÃ©sultats finaux, avec trÃ¨s peu d'unitÃ©s. Tant qu'il est possible de l'Ã©viter, il faut le faire.&#x20;

## Modifier les chemins d'accÃ¨s aux fichiers

Par dÃ©faut, si vous possÃ©dez une installation pour les clusters, HDFS est votre systÃ¨me de fichier par dÃ©faut. Par consÃ©quent, au passage sur le cluster, il est nÃ©cessaire de prÃ©ciser sur quel lecteur se situe votre fichier :

```
spark_read_parquet(sc, "file:///chemin.parquet")
```

C'est ce que l'on peut voir avec l'instruction file:/// qui prÃ©cise que le systÃ¨me de fichier local doit Ãªtre utilisÃ©.
