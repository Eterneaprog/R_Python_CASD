# üë©üè´ Clusters et haute performance

Si vous avez acc√®s √† un cluster dans votre projet, vous pouvez quitter le mode local et passer en mode cluster afin de disposer d'une plus grande quantit√© de ressources.

## Qu'est-ce qu'un cluster ?

Un cluster est un regroupement de machines de travail (les workers), sous la direction d'une machine ma√Ætre (le master). Le master se charge de distribuer le travail sur les diff√©rentes machines de travail et de collecter les r√©sultats. Cela permet de travailler de fa√ßon parall√®le, et donc de gagner du temps. Spark est un logiciel avec lequel vous allez √©changer pour faire fonctionner un cluster. Vous pouvez √©crire vos instructions dans une syntaxe plus proche du R : c'est SparkR, ou bien avec une syntaxe proche du Python : c'est PySpark ! Il est √† noter que l'on peut tout √† fait utiliser Spark sans cluster, c'est le [mode local](../spark/). De m√™me, on peut interagir avec un cluster avec d'autres logiciels que Spark. (Votre projet n'est pas n√©cessairement √©quip√© d'un cluster, vous pouvez vous rapprocher de votre chef de projet pour obtenir cette information.)

Voici un aper√ßu simplifi√© du fonctionnement d'un cluster Spark :

<figure><img src="../chapters/images/spark.png" alt=""><figcaption><p>Un exemple de cluster Spark</p></figcaption></figure>

Un cluster Spark est un outil puissant qui permet d'acc√©l√©rer grandement la vitesse d'ex√©cution de vos calculs. De plus, la puissance du cluster et sa taille sont plus modulables qu'une machine seule √† laquelle on ajoute des ressources : il suffit d'ajouter des workers. Cependant, l'utilisation de cet outil n'est pas toujours aussi ais√©e que lorsque l'on s'adresse √† une machine seule. Les diff√©rents articles suivants de cette section pr√©sentent comment adapter votre code pour effectuer la migration vers un cluster de calcul.&#x20;

De plus, il est important de noter qu'un cluster ajoute une ressource suppl√©mentaire √† √©valuer par rapport aux ressources traditionnellement prises en comptes pour les calculs ([CPU](../performance-calculs/ressources.md#le-processeur) et [RAM](../performance-calculs/ressources.md#la-memoire)) : le r√©seau. En effet, puisque les machines du parc doivent communiquer, il faut assurer que ces communications se fassent de fa√ßon rapide, car les temps de transferts d'informations sont perdus pour les calculs.

## Notion de files d'ex√©cutions

Dans un cluster Spark, on peut d√©finir des files d'ex√©cutions. L'int√©r√™t de ces files est de poss√©der des capacit√©s d√©di√©es et des usages bien pr√©cis. Ci-dessous, un exemple dans le cadre d'un cluster avec deux files pour cluster de 3 To de m√©moire :

<figure><img src="../.gitbook/assets/files_exec (1).png" alt=""><figcaption></figcaption></figure>

Une partie des ressources est d√©di√©e √† la production statistique, une autre file d√©die des ressources √† l'utilisation interactive et aux essais sur des plus petits volumes.&#x20;

L'int√©r√™t est de permettre le lancement de t√¢ches et la r√©cup√©ration de r√©sultats plus tard. On peut donc optimiser l'usage des ressources et les r√©partir dans le temps.

## Faut-il faire tourner son code sur un cluster plut√¥t qu'en local ?

Le co√ªt de cr√©ation du contexte Spark et la s√©lection des ressources √† attribuer est un processus couteux en termes de temps. Ce processus peut √™tre rentabilis√© dans le cas d'un long traitement, cette √©tape devenant n√©gligeable. Cependant, si le traitement est de taille raisonnable en mode local, passer en mode cluster peut repr√©senter une perte de temps en introduisant beaucoup d'√©tapes interm√©diaires, car la gestion ressource et le traitement sont de m√™me ordre de grandeur.&#x20;

Il faut donc r√©server l'utilisation du cluster aux traitements lourds, qui ne peuvent pas fonctionner en mode local parce qu'ils sont trop lourds (trop d'unit√©s, traitement couteux comme une jointure, etc). C'est en particulier le cas si votre cluster est √©quip√© d'une file d√©di√©e √† la production : elle ne doit pas faire l'objet d'une utilisation √† des fins de d√©veloppement ou de tests, une autre file est pr√©vue pour cela et doit √™tre privil√©gi√©e. De fa√ßon plus g√©n√©rale, il faut essayer de choisir des outils adapt√©s au besoin afin d'optimiser la consommation de ressources.

## Comment utiliser correctement un cluster quand un traitement justifie son utilisation ?

Passer en mode cluster n'est pas une formule magique pour gagner du temps. Avant d'effectuer un code tr√®s lourd sur un cluster, il faut v√©rifier plusieurs choses :

* Il fonctionne localement sur une petite quantit√© de donn√©e

Un code qui ne fonctionne pas localement n'a **aucune chance** de fonctionner avec un cluster. Cependant, l'effectuer en mode cluster complique consid√©rablement la recherche de l'erreur. En effet, on risque de m√©langer les probl√®mes venant du mode cluster et du code. Ce n'est pas une bonne chose. La bonne pratique est donc de syst√©matiquement effectuer un test local pour assurer le bon fonctionnement du code, sur une base r√©duite. Ainsi, si un code fonctionne en local, et pas en mode cluster, on est certain que l'erreur provient du passage au cluster, et on peut orienter la recherche de bugs en cons√©quences (sur les ressources, le r√©seau, etc.)

* Il utilise des fonctions compatibles avec un traitement distribu√©&#x20;

Un code qui utilise des fonctions qui ne sont pas distribu√©es (fonctions R standards par exemple), ne b√©n√©ficiera pas d'un passage sur cluster. Il faut donc √™tre s√ªr que le code est bien distribu√© avant de le passer sur un cluster de calcul.

* &#x20;Le code est bien optimis√©

Cela permet d'assurer que l'utilisation des ressources est optimale. Il est toujours pr√©f√©rable d'optimiser son code pour le faire tourner en local si c'est possible, plut√¥t que de le faire tourner sur un cluster tr√®s puissant. Le cluster ne doit pas √™tre une solution pour faire tourner de fa√ßon continue des codes mal optimis√©s qui prennent trop de temps, car leur conception est d√©faillante.

Les ressources d'un cluster sont partag√©es entre les membres d'une m√™me bulle et sont couteuses. Il convient d'√™tre raisonnable en communiquant ses traitements aux autres personnes utilisant le cluster, en utilisant le [spark UI](interfaces.md) pour identifier les ressources disponibles et en r√©servant des ressources ad√©quates pour son traitement. En g√©n√©ral, les clusters font l'objet d'une organisation interne avec des files d'ex√©cution. Il est important de respecter ces files en se renseignant aupr√®s de la personne m√©tier responsable du cluster.
