# üå† Spark en mode cluster

## Adapter la configuration

Pour effectuer des traitements avec Spark en mode cluster, il n'y a pas beaucoup de diff√©rences avec les traitements en mode local :&#x20;

{% hint style="danger" %}
Notez l'utilisation de l'instruction spark.yarn.queue qui permet de choisir sur quelle file il faut effectuer le traitement. Il peut ne pas exister de file par d√©faut. Par cons√©quent, ne pas pr√©ciser la file peut amener l'instruction SparkSession.builder() √† √©chouer.
{% endhint %}

{% tabs %}
{% tab title="PySpark" %}
```python
from pyspark.sql import SparkSession

# Configuration des ressources pour le cluster
spark = SparkSession.builder \
    .appName("MonApplication") \  # Nom de l'application Spark
    .config("spark.executor.memory", "8g") \  # M√©moire allou√©e par ex√©cuteur
    .config("spark.executor.cores", 4) \  # Coeurs par ex√©cuteur
    .config("spark.driver.memory", "4g") \  # M√©moire allou√©e au driver
    .config("spark.driver.cores", 2) \  # Coeurs allou√©s au driver
    .config("spark.yarn.queue", "prod") \ #Selection de la file d'ex√©cution
    .config("spark.master", "yarn") \
    .getOrCreate()
```
{% endtab %}

{% tab title="SparkR" %}
{% code overflow="wrap" %}
```r
# Chargement de la biblioth√®que SparkR
library(SparkR)

# Configuration des ressources pour le cluster
sparkR.session(
  master = "yarn",
  appName = "MonApplication",         # Nom de l'application Spark
  sparkConfig = list(
    "spark.executor.memory" = "8g",   # M√©moire allou√©e par ex√©cuteur
    "spark.executor.cores" = 4,       # Coeurs par ex√©cuteur
    "spark.driver.memory" = "4g",     # M√©moire allou√©e au driver
    "spark.driver.cores" = 2,         # Coeurs allou√©s au driver
    "spark.yarn.queue" = "prod"       # S√©lection de la file d'ex√©cution
  )
)
```
{% endcode %}
{% endtab %}

{% tab title="Sparklyr" %}
```r
library(sparklyr)
library(dplyr)

# Ins√©rer ici vos configurations personelles pour votre session
conf <- spark_config() 
conf["spark.driver.memory"] <- "16g"
conf["spark.executor.memory"] <- "8g"
conf["spark.executor.core"] <- 4
conf["spark.executor.instances"] <- 2
conf["spark.yarn.queue"] <- "prod"

# Cr√©ation de la connexion Sparklyr en mode cluster
sc <- spark_connect(master = "yarn", config = conf)
```

Une fois cette configuration effectu√©e, il faut effectuer vos traitements comme vous le feriez en mode local.

Attention √† l'instruction collect : elle ram√®ne le dataset vers la machine depuis laquelle vous acc√©dez votre session R ! Si le dataset est de taille tr√®s importante, cela peut causer une erreur m√©moire, car R chargera ce dataset dans la m√©moire de la machine et non sur disque. Cette instruction n'est √† r√©server qu'aux r√©sultats finaux, avec tr√®s peu d'unit√©s. Tant qu'il est possible de l'√©viter, il faut le faire.&#x20;

## Modifier les chemins d'acc√®s aux fichiers

Par d√©faut, si vous poss√©dez une installation pour les clusters, HDFS est votre syst√®me de fichier par d√©faut. Par cons√©quent, au passage sur le cluster, il est n√©cessaire de pr√©ciser sur quel lecteur se situe votre fichier :

```
spark_read_parquet(sc, "file:///chemin.parquet")
```

C'est ce que l'on peut voir avec l'instruction file:/// qui pr√©cise que le syst√®me de fichier local doit √™tre utilis√©.
{% endtab %}
{% endtabs %}
