# üêç Pyspark en mode cluster

## Adapter la configuration

Pour effectuer des traitements avec Sparklyr en mode cluster, il n'y a pas beaucoup de diff√©rences avec les traitements en mode local :

```python
from pyspark.sql import SparkSession

# Configuration des ressources pour le cluster
spark = SparkSession.builder \
    .appName("MonApplication") \  # Nom de l'application Spark
    .config("spark.executor.memory", "8g") \  # M√©moire allou√©e par ex√©cuteur
    .config("spark.executor.cores", 4) \  # Coeurs par ex√©cuteur
    .config("spark.driver.memory", "4g") \  # M√©moire allou√©e au driver
    .config("spark.driver.cores", 2) \  # Coeurs allou√©s au driver
    .config("spark.yarn.queue", "prod") \ #Selection de la file d'ex√©cution
    .config("spark.master", "yarn") \
    .getOrCreate()
```

Notez l'utilisation de l'instruction spark.yarn.queue qui permet de choisir sur quelle file il faut effectuer le traitement. Il peut ne pas exister de file par d√©faut. Par cons√©quent, ne pas pr√©ciser la file peut amener l'instruction SparkSession.builder() √† √©chouer.
