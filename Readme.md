# R et Python dans les bulles du CASD

<center><img src="/assets/images/CASD.png" alt="logo_casd" style="width:200px;"/></center>

Vous êtes habilité ou en cours d’habilitation pour travailler sur des données confidentielles auxquelles vous accéderez depuis le Centre d’Accès Sécurisé aux Données (CASD). Vous souhaitez travailler sur ces données avec le logiciel R, Python ou même Spark. Ce guide présente des conseils pour la réalisation de vos projets faisant intervenir ces langages ainsi que sur l’utilisation des outils de gestion de projets dans un contexte sans internet.

Ce guide est organisé par fiches thématiques. Ces fiches sont positionnées dans un ordre chronologique: elles permettent de partir d’un environnement de travail CASD vierge, jusqu’au développement de votre application, son optimisation et l'utilisation éventuelle de Spark. Cependant, il est tout à fait possible de se déplacer jusqu’à la fiche de votre choix si vous rencontrez un problème spécifique. Les mots clés de chaque chapitre vous permettent de vous diriger plus simplement.

En cas de problèmes, questions sur ce guide, idées pour l’améliorer, n’hésitez pas à nous contacter à [datascience@casd.eu](mailto:datascience@casd.eu). Nous serons ravis d’échanger avec vous et de vous aider à résoudre vos problèmes.

# Table des matières

1. [Organiser votre projet](chapters/1_organise.md) (Environnement conda / Arborescence de fichiers)
2. [Gérer les paquets associés au projet](chapters/2_packages.md) (Librairies / Paquets / Dépendances / Pip)
3. [Coder votre application avec R ou Python](chapters/3_code.md) (Editeurs de code / Exemples d'applications R et Python)
4. [Effectuer du travail collaboratif](chapters/4_collaborate.md) (Espace commun / Git / Répertoire git partagé / Chat dans la bulle)
5. [Optimiser les performances](chapters/5_performance.md) (Ressources / Libération mémoire / Parallélisation du code)
6. [Installer Spark et le paramétrer](chapters/6_spark.md) (SparklyR / PySpark / SparkSession / mode local et le mode cluster)
7. [Utiliser Spark pour accélérer ses calculs](chapters/7_spark_usage.md) (Adapter son code vers Spark / SQL/ Jointure)

## Bon code!

L'équipe Datascience du CASD
