# üìñ Table des mati√®res g√©n√©rale

## [Organiser et g√©rer son projet](../organiser/)

Cette section pr√©sente[ les environnements anaconda](../paquets/conda-env.md) pour un projet Python, ainsi que comment [organiser un dossier](../organiser/) contenant les fichiers d'une application R ou Python.

## [G√©rer les paquets associ√©s √† votre projet](../paquets/)

Tout ce qui est relatif aux [paquets/packages](../paquets/comprendre.md), [en R](../paquets/r.md) et [en Python](../paquets/python.md) !

## [Param√©trer votre √©diteur de code](../ide/)

Les [√©diteurs de codes](../ide/comprendre.md) sont des logiciels qui permettent de d√©velopper des programmes [R](../ide/rstudio.md), [Python](../ide/vscode.md) et [Spark](../ide/jupyterlab.md) en toute simplicit√© !

## [D√©velopper votre application](../developper/)

Vous trouverez ici des bonnes pratiques et des exemples [pour R ](../developper/r.md)et pour [Python](../developper/python.md).

## [Travail collaboratif](../collaborer/)

Vous travaillez avec des coll√®gues ? C'est par ici ! [Git](../collaborer/git.md), [l'espace commun](../collaborer/stockage-commun.md) et la [communication dans la bulle](../collaborer/etherpad.md) n'auront bient√¥t plus de secrets pour vous.

## [Optimiser les performances de calcul](../performance-calculs/)

Pour optimiser les performances de votre [programme Python](../performance-calculs/python.md) ou [R](../performance-calculs/r.md) et apprendre la [gestion des ressources](../performance-calculs/ressources.md), vous √™tes au bon endroit.

## [Optimiser les performances de stockage](../stockage/)

Les donn√©es sont volumineuses ? Vous avez besoin d'une solution de stockage efficace et adapt√©e ? Cette section peut vous aider √† faire votre choix entre [SQL](../stockage/sql/), [Parquet](../stockage/parquet.md) et [DuckDB](../stockage/duckdb/). Vous pourrez ensuite le mettre en place avec R et Python.

## [Spark](../spark/)

Vous voulez traiter des grands volumes √† vitesse grand V, [Spark ](../spark/comprendre.md)est fait pour vous. Voici comment [l'installer](../spark/installer.md), le manipuler [avec R](../spark/r.md) et [Python](../spark/python.md) et m√™me [apprendre √† lire comment Spark ex√©cute concr√®tement votre code.](../spark/dag/)

## [Gestion des clusters](../clusters/)

Si votre projet a acc√®s √† un [cluster de calcul](../clusters/comprendre.md), il faudra adapter votre code au niveau du [stockage](../clusters/stockage-distribue.md) et de la connexion Spark. Vous trouverez ici les ressources pour le faire !
