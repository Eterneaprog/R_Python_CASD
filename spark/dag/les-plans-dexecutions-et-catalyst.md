# üí£ Les plans d'ex√©cutions et Catalyst

## Qu'est-ce qu'un plan d'ex√©cution Spark ?

Lorsque vous faites ex√©cuter un programme, Spark interpr√®te votre code pour tenter d'optimiser sa r√©alisation. C'est le plan d'ex√©cution. C'est-√†-dire, la suite d'op√©rations logiques ou physiques que Spark doit effectuer pour obtenir le r√©sultat des transformations demand√©es sur les donn√©es. Le module charg√© de cette optimisation se nomme Catalyst. Il est une des raisons historiques du succ√®s de Spark : il apporte une optimisation extr√™me qui rend les programmes Spark tr√®s rapides √† ex√©cuter.

Sch√©matiquement, les choses sont organis√©es de la mani√®re suivante :&#x20;

<figure><img src="../../.gitbook/assets/Spark-exec.png" alt=""><figcaption><p>Optimisation du code Spark par le module Catalyst de Spark</p></figcaption></figure>

D'abord, le programme est analys√©, afin de comprendre la suite d'op√©rations voulues par l'utilisateur. Ensuite, on peut optimiser ce plan logique, par exemple, en filtrant d'abord les lignes avant une jointure, pour effectuer le moins d'op√©rations possibles.

Une fois le plan meilleur plan logique d√©termin√©, on peut g√©n√©rer plusieurs plans physiques pour le r√©aliser. Ces plans sont alors √©valu√©s par un mod√®le de co√ªt qui permet de d√©terminer quel plan physique est le moins couteux. Les op√©rations peuvent alors d√©buter.

## Pourquoi s'int√©resser aux plans et les optimiser ?

Malgr√© l'excellence technique de Catalyst, il n'est pas encore capable d'optimiser compl√®tement un code. Il est donc possible d'aider ce module en utilisant des techniques dans notre programme Spark. Comprendre le fonctionnement des plans g√©n√©r√©s par ce module est essentiel pour comprendre comment √©crire un programme Spark qui sera bien optimis√©.&#x20;

Lorsque l'on mobilise un programme Spark, surtout sur Cluster, il est fr√©quent que cela provoque du shuffling. C'est-√†-dire, le mouvement de donn√©es entre plusieurs n≈ìuds de notre cluster de calcul, pour que ces n≈ìuds puissent effectuer le calcul qui leur a √©t√© affect√©. Ces op√©rations sont tr√®s couteuses en temps. On cherche donc √† limiter ces op√©rations. On peut voir ces op√©rations dans les plans d'ex√©cution de Spark, et comprendre ce qui les a caus√©s. **L'enjeu des plans d'ex√©cution, c'est donc de diminuer le temps n√©cessaire pour obtenir un r√©sultat identique avec la m√™me quantit√© de donn√©es et les m√™mes ressources.**&#x20;

## Trouver son plan d'ex√©cution

Le plan d'ex√©cution associ√© √† un job/√† une commande Spark est toujours disponible sur Spark UI, l'interface graphique accessible depuis le navigateur.  Cela permet d'obtenir des statistiques sur l'utilisation des ressources √©tapes par √©tapes.&#x20;

Voici comment trouver le plan associ√© √† la suite de commandes issues de la documentation Spark (il s'agit d'instructions Scala, mais la technique reste valable avec SparklyR ou Pyspark !) :&#x20;

```scala
val textFile = spark.read.textFile("README.md")

textFile.map(line => line.split(" ").size).reduce((a, b) => if (a > b) a else b)
```

Cette suite de commande compte le nombre de lignes du fichier readme.md de spark de fa√ßon distribu√©e. Voyons comment obtenir le plan (DAG) associ√© √† cette commande :&#x20;

D'abord, on liste les √©tapes des Jobs dans l'onglet stages

<figure><img src="../../.gitbook/assets/DAG-1.PNG" alt=""><figcaption></figcaption></figure>

Ensuite, on ouvre la commande ex√©cut√©e :

<figure><img src="../../.gitbook/assets/DAG-2.Png" alt=""><figcaption></figcaption></figure>

Enfin, on obtient le sch√©ma qui repr√©sente le DAG en cliquant sur DAG Visualization :

<figure><img src="../../.gitbook/assets/DAG-3.png" alt=""><figcaption><p>Enfin, le DAG (plan d'ex√©cution) est disponible en cliquant sur DAG vizualisation</p></figcaption></figure>

Les plans d'ex√©cutions sont diff√©renci√©s selon le mode local ou cluster. En particulier le plan physique retenu. En local, toutes les op√©rations se font sur la m√™me machine, il n'y a donc pas la phase de n√©gociations de ressources pr√©sente dans un cluster manag√© avec Yarn par exemple. Les plans locaux sont donc g√©n√©ralement plus faciles √† lire pour un d√©butant puisqu'ils mobilisent moins d'√©tapes.

## Comprendre le fonctionnement de Catalyst

Un des objectifs principaux de Catalyst est de pr√©parer un plan d'ex√©cution qui √©vite les mouvements de donn√©es entre les n≈ìuds en mode cluster (c'est le shuffling). Cette √©tape est extr√™mement couteuse et diff√©rentes techniques existent pour l'√©viter. De plus, Spark effectue des traitements en parall√®le, m√™me en mode local, via les diff√©rents c≈ìurs du processeur. Par cons√©quent, le plan pr√©par√© doit pouvoir √™tre distribu√© au mieux. Pour cela, il est possible d'utiliser les techniques pr√©sent√©es dans la suite de cette section.

## Techniques utilis√©es par Catalyst pour optimiser le code

Nous allons voir quatre techniques majeures utilis√©es par le module Catalyst pour optimiser les traitements Spark. Cela nous permettra par la suite de comprendre comment optimiser notre code Spark, en fonction de ce que l'on lit dans le diagramme DAG pr√©sent√© pr√©c√©demment.

### Le pipelining

Dans une √©tape, si plusieurs transformations sont de type Narrow, elles peuvent √™tre misent dans un pipeline. C'est-√†-dire, √™tre enchain√©es par Spark sans mouvements de donn√©es. Par exemple, l'application d'un filtre, puis d'une Union entre deux tables. Lors d'un pipeline, Spark est capable d'identifier les d√©pendances (partitions) d'un tableau, et donc d'encha√Æner les √©tapes d√®s que les r√©sultats sont disponibles, sans attendre l'ensemble des r√©sultats pour toutes les partitions.

Des op√©rations qui font l'objet d'un pipeline sont donc moins couteuses √† ex√©cuter. Cela se mat√©rialise dans le DAG par l'enchainement de ces √©tapes en un seul bloc.

### La concurrence des √©tapes

Spark est nativement distribu√©. Cela signifie qu'il ex√©cute plusieurs t√¢ches en parall√®le. Ceci est possible lorsque les diff√©rentes transformations ne sont pas reli√©es entre elles. La concurrence ex√©cute de fa√ßon parall√®le diff√©rentes √©tapes ind√©pendantes. Cela se produit en particulier lorsqu'il n'est pas n√©cessaire d'attendre le r√©sultat d'une transformation pr√©c√©dente pour d√©marrer les calculs de la transformation suivante.\
\
Par exemple : si un pipeline est d√©fini et est ex√©cut√© sur chaque n≈ìud de calcul, inutile d'attendre le r√©sultat de l'√©tape interm√©diaire sur le n≈ìud 2 pour calculer la suite des op√©rations du n≈ìud 1 si sa propre op√©ration interm√©diaire est achev√©e. On peut poursuivre les op√©rations du pipeline sur le n≈ìud 1.

### La fusion de t√¢ches cons√©cutives

Il s'agit d'une technique proche du pipelining. Lorsque plusieurs t√¢ches peuvent √™tre fondues en une seule, Spark les ex√©cute en m√™me temps afin de gagner du temps. C'est une √©tape suppl√©mentaire par rapport au pipeline, lorsqu'il est possible d'effectuer deux traitements en m√™me temps et non plus √† la suite. Cela permet de faire des gains de temps non n√©gligeables en ne dupliquant pas certains calculs.

Par exemple, deux filtres appliqu√©s sur deux variables diff√©rentes √† la suite sur une table peuvent √™tre fusionn√©s et seront ex√©cut√©s ensemble.

### La data locality

Spark ex√©cute prioritairement les traitements l√† o√π les donn√©es sont d√©j√† pr√©sentes. L√† encore, l'objectif est de minimiser les mouvements de donn√©es. Cette priorisation est prise en compte lors de la planification par le module Catalyst. Le partitionnement des tables sur les n≈ìuds de donn√©es est un √©l√©ment particuli√®rement important pour b√©n√©ficier de cette technique. Si une table est bien partitionn√©e, il est possible de minimiser grandement les mouvements de donn√©es entre les n≈ìuds, m√™me lors d'un group by !

L'objectif de cette technique est encore d'√©viter les mouvements de donn√©es (shuffle).
