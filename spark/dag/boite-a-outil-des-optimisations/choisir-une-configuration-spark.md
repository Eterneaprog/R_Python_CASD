# üîß Choisir une configuration Spark

Dans certains cas, les donn√©es d√©passent la taille de la m√©moire allou√©e au traitement. S'il est possible de le faire, on peut envisager l'augmentation de la m√©moire pour que l'ensemble des donn√©es soient charg√©es en m√©moire. Sinon, cela provoque la mont√©e et descente intempestive de donn√©es entre disque et m√©moire pour que les donn√©es puissent √™tre lues par Spark. Ce n'est pas optimal.

Si vous avez d√©tect√© une configuration insuffisante, vous pouvez apporter des modifications √† la configuration de Spark pour votre programme :

* [Modifier sa configuration Spark](../../r.md#configurer-spark-en-mode-local)

Voici les param√®tres qui vont particuli√®rement nous int√©resser dans le cas d'une telle optimisation en cluster :

<table><thead><tr><th width="236.33333333333331" align="center">Param√®tre</th><th width="98" align="center">D√©faut</th><th align="center">Description</th></tr></thead><tbody><tr><td align="center"><strong>spark.executor.instances</strong></td><td align="center">2</td><td align="center">Le nombre d'instances de Spark utilis√©es</td></tr><tr><td align="center"><strong>spark.executor.cores</strong></td><td align="center">1</td><td align="center">Le nombre de c≈ìurs par instances</td></tr><tr><td align="center"><strong>spark.executor.memory</strong></td><td align="center">1g</td><td align="center">La quantit√© de m√©moire par instance</td></tr></tbody></table>

