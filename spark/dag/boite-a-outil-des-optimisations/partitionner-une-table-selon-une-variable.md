# ğŸ§© Partitionner une table selon une variable

## Partitionnement ?

Le partitionnement pour un dataframe Spark, c'est une faÃ§on de le ranger, de l'organiser, de le stocker. Cela ne change pas le contenu de la table ou les lignes, mais comment on va diviser cette table en sous-ensembles.&#x20;

On appelle chacun de ces sous-ensembles partition. Il peut y en avoir plus ou moins selon le critÃ¨re pour construire les sous-ensembles. On peut partitionner de faÃ§on purement mathÃ©matique, en demandant un nombre fixe de partitions que l'on traitera de faÃ§on indÃ©pendante, comme des batchs. Mais on peut aussi partitionner de faÃ§on 'mÃ©tier', afin de regrouper les donnÃ©es d'une maniÃ¨re qui a du sens par rapport au traitement. Par exemple, diviser une table contenant des vÃ©hicules par marque. S'il y a 10 marques de voitures dans la table, on obtiendra 10 partitions Ã  traiter.

## Pourquoi partitionner ?

Partitionner, cela permet de tirer pleine puissance des architectures distribuÃ©es. Une bonne partition, cela permet de minimiser les mouvements de donnÃ©es lors des traitements. C'est donc un gain de performance trÃ¨s important.&#x20;

### Une rÃ¨gle gÃ©nÃ©rale de partitionnement

> La rÃ¨gle gÃ©nÃ©rale pour trouver les variables par lesquelles on doit partitionner est de regarder quelles variables sont utilisÃ©es pour faire des group by et des filtres Ã  plusieurs reprises.

Par exemple, dans l'exemple prÃ©cÃ©dent sur les vÃ©hicules, si l'on va ensuite calculer la moyenne de prix des vÃ©hicules pour chaque marque, le temps de calcul va Ãªtre drastiquement rÃ©duit : il suffit d'appliquer la fonction moyenne Ã  chaque sous-ensemble. Cela signifie concrÃ¨tement qu'au moment d'effectuer un group by (instruction de nature wide, donc couteuse, et qui engendre des mouvements de donnÃ©es), aucun mouvement ne se produira. En effet, la moyenne sera simplement appliquÃ©e Ã  l'endroit oÃ¹ chaque partition est stockÃ©e (sur chaque worker).&#x20;

Observez ce schÃ©ma qui rÃ©sume cet exemple :&#x20;

<figure><img src="../../../.gitbook/assets/partition.png" alt=""><figcaption></figcaption></figure>

L'utilisation d'une partition par la variable marque permet d'Ã©viter l'envoi des donnÃ©es entre les deux nÅ“uds puisque toutes les donnÃ©es du calcul sont dÃ©jÃ  accessibles par celui-ci ! Il n'y a donc pas de shuffle, qui est trÃ¨s couteux en temps et en ressources. Admettons que je souhaite ensuite calculer l'Ã©cart type, puis le maximum et minimum de chaque marque, on effectue des gains de temps pour chacune de ces opÃ©rations. Cela peut donc se rÃ©vÃ©ler trÃ¨s rentable. De plus, mÃªme dans le cas d'un calcul de moyenne gÃ©nÃ©ral, ce choix de partition n'est pas pÃ©nalisant ! Ici, on peut donc parler de partitionnement 'naturel'.

Une partition peut Ãªtre vue comme prÃ©-traiter les donnÃ©es avec un group-by. Cela peut Ãªtre payant si on va de toute faÃ§on appliquer un tel group by Ã  plusieurs reprises.&#x20;

### Les cas dÃ©favorables

Cependant, il faut aussi Ãªtre prudent lorsque l'on partitionne. Si on choisit une partition inadaptÃ©e au traitement, cela peut engendrer encore plus de mouvements de donnÃ©es ! En effet, une table partitionnÃ©e avec beaucoup de partitions est plus longue Ã  interroger lorsque l'on mobilise des donnÃ©es dans beaucoup de partitions. &#x20;

Voici le rÃ©sultat d'un benchmark que nous avons effectuÃ© sur une table :

<table><thead><tr><th width="409">RequÃªte / Partitions </th><th width="113" align="center">2</th><th width="103" align="center">5</th><th align="center">1000</th></tr></thead><tbody><tr><td>RequÃªte sur une colonne qui a servi au partitionnement</td><td align="center">74,50%</td><td align="center">46,30%</td><td align="center">16,66%</td></tr><tr><td>RequÃªte vers une autre colonne</td><td align="center">89,51%</td><td align="center">191,01%</td><td align="center">556,99%</td></tr><tr><td>Select distinct(*)</td><td align="center">136,79%</td><td align="center">163,68%</td><td align="center">1194,88%</td></tr></tbody></table>

On voit que le gain de temps est rÃ©el sur les requÃªtes avec des colonnes qui ont servi au partitionnement. Cependant, cela fait augmenter le temps de calcul sur les requÃªtes qui mobilisent plusieurs partitions. La meilleure solution est donc souvent de choisir une partition avec un nombre limitÃ© de valeurs afin d'Ã©viter l'Ã©cueil principal : faire trop de partitions.

Il n'existe pas de partitionnement idÃ©al ou par dÃ©faut, il faut toujours rÃ©flÃ©chir Ã  l'utilisation des donnÃ©es pour dÃ©terminer le partitionnement Ã  utiliser.

## Comment partitionner ?

{% tabs %}
{% tab title="PySpark" %}
Par nombre de partitions :

```python
my_dataframe.repartition(10)
```

ou par variable(s) :&#x20;

```python
my_dataframe.repartition("my_variable")
```

On peut aussi partitionner avec plusieurs variables, en remplaÃ§ant la chaine de caractÃ¨re par un vecteur.
{% endtab %}

{% tab title="SparkR" %}
Par nombre de partitions :

```r
repartitioned_df <- repartition(my_dataframe, 10)
```

ou par variable(s) :&#x20;

```r
repartitioned_df <- repartition(my_dataframe, my_dataframe$my_variable)
```

On peut aussi partitionner avec plusieurs variables, en remplaÃ§ant la variable par un vecteur.
{% endtab %}

{% tab title="SparklyR" %}
Par nombre de partitions :

```r
sdf_repartition(my_dataframe, partitions = 10, partition_by = NULL) 
```

ou par variable(s) :&#x20;

```r
sdf_repartition(my_dataframe, partitions = NULL, partition_by = "my_variable") 
```

On peut aussi partitionner avec plusieurs variables, en remplaÃ§ant la chaine de caractÃ¨re par un vecteur.
{% endtab %}
{% endtabs %}

## Exemples de partitionnements par variables pertinents :

Si on accÃ¨de Ã  des donnÃ©es gÃ©ographiques, il est intÃ©ressant de partitionner par rÃ©gion/dÃ©partement/ville. On va gagner beaucoup de temps lors de la lecture par la suite.

Imaginons que l'on Ã©tudie une table sur des individus, contenant des donnÃ©es de santÃ© ou des donnÃ©es Ã©conomiques, selon le contexte d'utilisation et selon la maniÃ¨re mÃªme dont la table est construite, le partitionnement peut totalement changer.

Si dans cette table, plusieurs lignes correspondent Ã  des informations sur le mÃªme individu, et donc qu'il n'est pas unique, on peut partitionner avec l'identifiant de l'individu. C'est particuliÃ¨rement efficace si on va effectuer des traitements par individus par la suite.&#x20;

Si dans cette table, chaque individu est unique, et que l'on va chercher Ã  faire des groupes, le partitionnement par individu est inutile. En effet, on ne fera pas de regroupement puisqu'un individu correspond Ã  une ligne dans la table. Par contre, on peut partitionner par la variable Sexe et Age par exemple.

La documentation officielle sur le [repartitionnement d'une table](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.repartition.html)

## La rÃ¨gle gÃ©nÃ©rale si on ne peut pas partitionner par variable

En rÃ¨gle gÃ©nÃ©rale, le nombre de partitions d'une table doit Ãªtre contenu entre :&#x20;

Au minimum : 2 x le nombre de cÅ“urs choisis pour lâ€™application

Au maximum : au moins 100ms de temps d'exÃ©cution par partition, au dela, c'est que la table est trop partitionnÃ©e, et donc on perd du temps lors des opÃ©rations qui nÃ©cÃ©ssitent un shuffling.

Cependant, cette rÃ¨gle gÃ©nÃ©rale n'est pas vraiment la meilleure faÃ§on de procÃ©der. Elle ne tient pas compte du contexte spÃ©cifique mÃ©tier dans lequel la table sera utilisÃ©e. Souvent, il est bien plus intÃ©ressant d'utiliser ce contexte pour partitionner de maniÃ¨re intelligente.
