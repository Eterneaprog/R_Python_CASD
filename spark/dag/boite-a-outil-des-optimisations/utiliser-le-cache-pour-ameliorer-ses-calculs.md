# üìù Utiliser le cache pour am√©liorer ses calculs

Un cache est un espace de stockage temporaire dans lequel on place des objets dont on souhaite se resservir plus tard, afin de ne pas avoir √† les recalculer. Ces objets ne sont pas suffisamment importants pour justifier une persistance compl√®te sur disque, car ce ne sont pas des r√©sultats finaux.

## Principe de fonctionnement

<figure><img src="../../../.gitbook/assets/Cache.png" alt=""><figcaption></figcaption></figure>

Ce sch√©ma montre la diff√©rence entre un fonctionnement de Spark en utilisant le cache et sans le cache. √Ä gauche, la chaine d'ex√©cution est d√©clench√©e en 1 par la pr√©sence de l'action (un `show` ou un `count` par exemple). Cette chaine implique la mont√©e en m√©moire de la table. Pendant le temps o√π le calcul demand√© par l'action est en traitement, la table est bien en m√©moire. Elle est cependant d√©charg√©e √† la fin de 4 pour lib√©rer la m√©moire et continuer le programme.&#x20;

Si on appelle la m√™me table par la suite, Spark effectue de nouveau le bloc de chargement. Il a connaissance du nom de la table bien s√ªr, mais il doit ex√©cuter de nouveau le bloc de chargement puisque cette table n'est plus en m√©moire. Dans le code, m√™me si on ne fait pas deux fois l'instruction read\_csv, celle-ci est en pratique jou√©e deux fois afin de construire la table quand c'est n√©cessaire.

C'est ici que la diff√©rence intervient avec la situation avec cache. Dans le sch√©ma de droite, la table est mise en cache apr√®s le chargement et donc reste en m√©moire pour la dur√©e de la session. Elle est donc r√©utilis√©e sans co√ªt lors de l'appel d'une transformation apr√®s une action (5-6). C'est donc plus rapide.&#x20;

### Avantages et inconv√©nients

Dans le premier exemple, sans cache, le chargement est effectu√© 2 fois, donc le temps utilis√© est plus long. En effet, puisqu'il s'agit de la m√™me table, c'est int√©ressant de la mettre en cache. On peut donc dire que lorsqu'une table sera appel√©e plusieurs fois dans le code, apr√®s plusieurs actions qui produisent des r√©sultats, c'est int√©ressant de la mettre en cache.&#x20;

Ce n'est pas le cas si on va enchainer les transformations et ne produire qu'un seul r√©sultat : dans ce cas, on ne gagnera pas de temps de chargement, et la table restera dans la m√©moire pour l'ensemble de la session. Cela prive donc la suite des calculs de ressources utiles en stockant dans la m√©moire une table de fa√ßon inutile.

## Applications

### Chargement des tables

La premi√®re application de la mise en cache est √©videmment lors du chargement des tables comme dans l'exemple ci-dessus.

Avec l'instruction `spark_read_csv` de sparklyr par exemple, on peut utiliser l'option memory = TRUE / FALSE. Cette option charge la table en m√©moire dans un cas, alors que dans l'autre, elle va simplement cr√©er un lien logique entre le nom de la table et le fichier, sans effectuer de chargement.&#x20;

Autrement, avec PySpark, il faut utiliser `.cache()` qui permet d'obtenir le m√™me r√©sultat.

### Utiliser un cache ou [HDFS](../../../clusters/hdfs.md) pour stocker un r√©sultat interm√©diaire

Pour √©viter le recalcul de certains r√©sultats, utiliser un cache ou stocker le r√©sultat est une option envisageable lorsque beaucoup de calculs sont effectu√©s. Il est possible d'appliquer la m√™me strat√©gie qu'au chargement des tables, mais sur un DataFrame qui a d√©j√† √©t√© modifi√©, en le mettant en cache.

Attention cependant √† l'abus d'utilisation du cache : cette op√©ration ne doit √™tre utilis√©e que dans un objectif d'optimisation, pas de fa√ßon syst√©matique apr√®s chaque calcul, sous peine de consommer l'ensemble de la m√©moire sans gain de vitesse. En particulier, il ne faut pas mettre en cache un jeu de donn√©es qui ne tient pas en m√©moire.

Les ressources concernant la mise en cache avec Sparklyr sont disponibles ici :

{% embed url="https://spark.posit.co/guides/caching.html" %}

Ici, la documentation de la fonction PySpark pour mettre en cache :

{% embed url="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.cache.html" %}
