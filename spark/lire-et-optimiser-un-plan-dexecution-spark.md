# üë©üè´ Lire et optimiser un plan d'ex√©cution Spark

**Attention :** cet article pr√©sente des notions avanc√©es en Spark. Ces notions ne sont pas n√©cessaires pour faire fonctionner le logiciel : il est tout √† fait possible de faire du Spark sans elles. Il s'agit d'optimisations pour les personnes qui effectuent du Spark en production, et pour qui le temps d'ex√©cution d'un programme doit √™tre diminu√©. \
\
Cet article n'est pas recommand√© pour les d√©butants en Spark, m√™me s'il peut √™tre lu par tous.

## Qu'est-ce qu'un plan d'ex√©cution Spark ?

Lorsque vous faites ex√©cuter un programme, Spark interpr√®te votre code pour tenter d'optimiser sa r√©alisation. C'est le plan d'ex√©cution. C'est-√†-dire, la suite d'op√©rations logiques ou physiques que Spark doit effectuer pour obtenir le r√©sultat des transformations demand√©es sur les donn√©es. Le module charg√© de cette optimisation se nomme Catalyst. Il est une des raisons historiques du succ√®s de Spark : il apporte une optimisation extr√™me qui rend les programmes Spark tr√®s rapides √† ex√©cuter.

Sch√©matiquement, les choses sont organis√©es de la mani√®re suivante :&#x20;

<figure><img src="../.gitbook/assets/Spark-exec.png" alt=""><figcaption><p>Optimisation du code Spark par le module Catalyst de Spark</p></figcaption></figure>

D'abord, le programme est analys√©, afin de comprendre la suite d'op√©rations voulues par l'utilisateur. Ensuite, on peut optimiser ce plan logique, par exemple, en filtrant d'abord les lignes avant une jointure, pour effectuer le moins d'op√©rations possibles.

Une fois le plan meilleur plan logique d√©termin√©, on peut g√©n√©rer plusieurs plans physiques pour le r√©aliser. Ces plans sont alors √©valu√©s par un mod√®le de co√ªt qui permet de d√©terminer quel plan physique est le moins couteux. Les op√©rations peuvent alors d√©buter.

## Pourquoi s'int√©resser aux plans et les optimiser ?

Malgr√© l'excellence technique de Catalyst, il n'est pas encore capable d'optimiser compl√®tement un code. Il est donc possible d'aider ce module en utilisant des techniques dans notre programme Spark. Comprendre le fonctionnement des plans g√©n√©r√©s par ce module est essentiel pour comprendre comment √©crire un programme Spark qui sera bien optimis√©.&#x20;

Lorsque l'on mobilise un programme Spark, surtout sur Cluster, il est fr√©quent que cela provoque du shuffling. C'est-√†-dire, le mouvement de donn√©es entre plusieurs n≈ìuds de notre cluster de calcul, pour que ces n≈ìuds puissent effectuer le calcul qui leur a √©t√© affect√©. Ces op√©rations sont tr√®s couteuses en temps. On cherche donc √† limiter ces op√©rations. On peut voir ces op√©rations dans les plans d'ex√©cution de Spark, et comprendre ce qui les a caus√©s. **L'enjeu des plans d'ex√©cution, c'est donc de diminuer le temps n√©cessaire pour obtenir un r√©sultat identique avec la m√™me quantit√© de donn√©es et les m√™mes ressources.**&#x20;

## Trouver son plan d'ex√©cution

Le plan d'ex√©cution associ√© √† un job/√† une commande Spark est toujours disponible sur Spark UI, l'interface graphique accessible depuis le navigateur.  Cela permet d'obtenir des statistiques sur l'utilisation des ressources √©tapes par √©tapes.&#x20;

Voici comment trouver le plan associ√© √† la suite de commandes issues de la documentation Spark (il s'agit d'instructions Scala, mais la technique reste valable avec SparklyR ou Pyspark !) :&#x20;

```scala
val textFile = spark.read.textFile("README.md")

textFile.map(line => line.split(" ").size).reduce((a, b) => if (a > b) a else b)
```

Cette suite de commande compte le nombre de lignes du fichier readme.md de spark de fa√ßon distribu√©e. Voyons comment obtenir le plan (DAG) associ√© √† cette commande :&#x20;

D'abord, on liste les √©tapes des Jobs dans l'onglet stages

<figure><img src="../.gitbook/assets/DAG-1.PNG" alt=""><figcaption></figcaption></figure>

Ensuite, on ouvre la commande ex√©cut√©e :

<figure><img src="../.gitbook/assets/DAG-2.Png" alt=""><figcaption></figcaption></figure>

Enfin, on obtient le sch√©ma qui repr√©sente le DAG en cliquant sur DAG Visualization :

<figure><img src="../.gitbook/assets/DAG-3.png" alt=""><figcaption><p>Enfin, le DAG (plan d'ex√©cution) est disponible en cliquant sur DAG vizualisation</p></figcaption></figure>

Les plans d'ex√©cutions sont diff√©renci√©s selon le mode local ou cluster. En particulier le plan physique retenu. En local, toutes les op√©rations se font sur la m√™me machine, il n'y a donc pas la phase de n√©gociations de ressources pr√©sente dans un cluster manag√© avec Yarn par exemple. Les plans locaux sont donc g√©n√©ralement plus faciles √† lire pour un d√©butant puisqu'ils mobilisent moins d'√©tapes.

## Optimisations au code Spark et fonctionnement de Catalyst

Un des objectifs principaux de Catalyst est de pr√©parer un plan d'ex√©cution qui √©vite les mouvements de donn√©es entre les n≈ìuds en mode cluster (c'est le shuffling). Cette √©tape est extr√™mement couteuse et diff√©rentes techniques existent pour l'√©viter. De plus, Spark effectue des traitements en parall√®le, m√™me en mode local, via les diff√©rents c≈ìurs du processeur. Par cons√©quent, le plan pr√©par√© doit pouvoir √™tre distribu√© au mieux.

Un rappel pr√©alable : Spark diff√©rencie les transformations et les actions. Une transformation prend un tableau en entr√©e, et retourne un autre tableau. Une action prend un tableau en entr√©e et retourne autre chose qu'un tableau. \
Cette diff√©rence est tr√®s importante √† cause du ph√©nom√®ne de lazy evaluation. Comme nous l'avons vu, Catalyst optimise le code en r√©organisant les √©tapes. Cela ne peut √™tre fait que lorsque l'on ex√©cute plusieurs lignes √† la fois. Par cons√©quent, Spark attend qu'une action (show, write, collect, count, ...), soit d√©clench√©e afin d'effectuer les traitements. C'est pour cela que faire un groupBy est instantan√© dans une cellule de Jupyter Notebook, mais qu'afficher le r√©sultat avec un show dans une autre cellule ne l'est pas : Spark ex√©cute physiquement l'instruction groupBy au moment de l'activation de la cellule d'affichage.\
\
Nous allons voir cinq techniques majeures utilis√©es par le module Catalyst pour optimiser les traitements Spark. Cela nous permettra par la suite de comprendre comment optimiser notre code Spark, en fonction de ce que l'on lit dans le diagramme DAG pr√©sent√© pr√©c√©demment.

### D√©pendances Narrow contre Wide

Spark introduit la notion de d√©pendance entre deux tableaux pour les transformations qu'il propose. Il en existe deux types : Narrow et Wide. On dit d'une transformation qu'elle poss√®de une d√©pendance Narrow si chaque partition du r√©sultat d√©pend d'une partition de l'entr√©e. √Ä l'inverse, une transformation poss√®de des d√©pendances Wide si les partitions du r√©sultat poss√®dent des donn√©es de diff√©rentes partitions d'origine. Observez plut√¥t le sch√©ma suivant :&#x20;

<figure><img src="../.gitbook/assets/NarrowVSWide (1).png" alt=""><figcaption></figcaption></figure>

Les transformations Spark dites de type Narrow sont en autres :

* Union
* Map
* Filter
* Certaines jointures lorsque les donn√©es sont partitionn√©es selon leurs cl√©s.

Par exemple, lors d'un filtre, on peut appliquer le filtre aux donn√©es de chaque n≈ìud. Il est inutile de mobiliser des donn√©es de plusieurs n≈ìuds pour cette op√©ration. Cela correspond au fonctionnement √† gauche du sch√©ma.

Ce n'est pas le cas pour :&#x20;

* GroupBy
* Repartition
* Intersection
* Distinct
* Join

Ces transformations sont de type wide. Par cons√©quent, lorsque vous les appliquez, elles forcent presque syst√©matiquement des mouvements de donn√©es. Par exemple, dans le cas d'un GroupBy, il est bien n√©cessaire d'utiliser les donn√©es des diff√©rents n≈ìuds afin d'effectuer les groupements demand√©s. Il y a donc shuffling.

Les op√©rations de type Narrow peuvent √™tre facilement enchain√©es, r√©parties sur diff√©rents n≈ìuds, et sont donc moins couteuses. Ce n'est pas le cas des op√©rations wide.

### Le pipelining

Dans une √©tape, si plusieurs transformations sont de type Narrow, elles peuvent √™tre misent dans un pipeline. C'est-√†-dire, √™tre enchain√©es par Spark sans mouvements de donn√©es. Par exemple, l'application d'un filtre, puis d'une Union entre deux tables. Lors d'un pipeline, Spark est capable d'identifier les d√©pendances (partitions) d'un tableau, et donc d'encha√Æner les √©tapes d√®s que les r√©sultats sont disponibles, sans attendre l'ensemble des r√©sultats pour toutes les partitions.

\[Image d'instructions ayant fait l'objet d'un pipeline]

Des op√©rations qui font l'objet d'un pipeline sont donc moins couteuses √† ex√©cuter. Cela se mat√©rialise dans le DAG par l'enchainement de ces √©tapes en un seul bloc.

### La concurrence des √©tapes

Spark est nativement distribu√©. Cela signifie qu'il ex√©cute plusieurs t√¢ches en parall√®le. Ceci est possible lorsque les diff√©rentes transformations ne sont pas reli√©es entre elles. La concurrence ex√©cute de fa√ßon parall√®le diff√©rentes √©tapes ind√©pendantes. Cela se produit en particulier lorsqu'il n'est pas n√©cessaire d'attendre le r√©sultat d'une transformation pr√©c√©dente pour d√©marrer les calculs de la transformation suivante.\
\
Par exemple : si un pipeline est d√©fini et est ex√©cut√© sur chaque noeud de calcul, inutile d'attendre le r√©sultat de l'√©tape interm√©diaire sur le noeud 2 pour calculer la suite des op√©rations du noeud 1 si ca propre op√©ration interm√©diaire est achev√©e. On peut poursuivre les op√©rations du pipeline sur le noeud 1.

### La fusion de t√¢ches cons√©cutives

Il s'agit d'une technique proche du pipelining. Lorsque plusieurs t√¢ches peuvent √™tre fondues en une seule, Spark les ex√©cute en m√™me temps afin de gagner du temps. C'est une √©tape suppl√©mentaire par rapport au pipeline, lorsqu'il est possible d'effectuer deux traitements en m√™me temps et non plus √† la suite. Cela permet de faire des gains de temps non n√©gligeables en ne dupliquant pas certains calculs.

Par exemple, deux filtres appliqu√©s sur deux variables diff√©rentes √† la suite sur une table peuvent √™tre fusionn√©s et seront ex√©cut√©s ensemble.

### La data locality

Spark ex√©cute prioritairement les traitements l√† o√π les donn√©es sont d√©j√† pr√©sentes. L√† encore, l'objectif est de minimiser les mouvements de donn√©es. Cette priorisation est prise en compte lors de la planification par le module Catalyst. Le partitionnement des tables sur les noeuds de donn√©es est un √©l√©ment particuli√®rement important pour b√©n√©ficier de cette technique.

L'objectif de cette technique est encore d'√©viter les mouvements de donn√©es (shuffle).

## Comment aider Catalyst dans votre code et gagner du temps ?

Nous avons vu les techniques avanc√©es que Catalyst met en place pour optimiser les temps de calculs. Voyons maintenant comment nous pouvons en tirer profit par un code optimal en tenant compte du comportement de ce module.&#x20;

### √âtape 1 : D√©tecter les engorgements via le diagramme DAG

Nous avons appris o√π lire un diagramme DAG pr√©c√©demment. Ce que l'on recherche dans ce diagramme sont les engorgements. C'est-√†-dire, les √©tapes qui provoquent un ralentissement en bloquant l'ensemble du code. Cela se mat√©rialise souvent par la pr√©sence d'un shuffle, qui sont souvent la cons√©quence d'une instruction de nature Wide :

<figure><img src="../.gitbook/assets/example partition.png" alt=""><figcaption></figcaption></figure>

Ici, on voir que l'engorgement se fait au moment o√π l'on passe de l'√©tape 8 √† 9, car il y a lecture et √©criture de 58 Giga de donn√©es entre les deux √©tapes. C'est √† dire, transfert de donn√©es.&#x20;

On peut aussi regarder quelles sont les √©tapes qui consomment le plus de temps (de CPU et de RAM dans le tableau en dessous √©galement). Cet exemple de Apache Spark montre les √©tapes du calcul de Pi :

<figure><img src="../.gitbook/assets/summary.PNG" alt=""><figcaption></figcaption></figure>

On peut alors d√©terminer dans notre code ce qui est responsable de la dur√©e du traitement. On peut ensuite prendre une d√©cision adapt√©e en apportant des modifications.

### √âtape 2 : Utiliser une technique pour optimiser

Il existe diff√©rentes techniques afin d'optimiser son code, √† adapter selon la cause de l'engorgement d√©tect√©e √† l'√©tape 1. Parmis celles-ci, on trouve, entre autres :&#x20;

#### Le choix de la [strat√©gie de jointure](https://spark.apache.org/docs/latest/sql-performance-tuning.html#join-strategy-hints-for-sql-queries)

Selon la taille des tables √† joindre par rapport √† la m√©moire, on peut indiquer √† Spark une certaine technique de jointure plus ou moins adapt√©e :&#x20;

1 - Broadcast Hash Join  : si une des tables est petite et l'autre grande, c'est un bon choix. Attention : elle ne supporte que le crit√®re d'√©galit√© pour la jointure.

2 - Sort Merge Join : cette strat√©gie est efficace en toute circonstances de taille : elle est pr√©vue pour d√©border sur le disque car elle n'utilise pas de table de hashache. \
Attention : elle ne supporte que le crit√®re d'√©galit√© pour la jointure.

3 - Shuffle Hash Join : si les deux tables sont grandes, cette strat√©gie est envisageable car elle m√©lange le hashage et le shuffling. \
Attention : elle ne supporte que le crit√®re d'√©galit√© pour la jointure et peut ne pas fonctionner si la taille d√©passe la m√©moire allou√©e au traitement.

4 - Broadcast Nested Loop Join : cette strat√©gie est int√©ressante car elle offre la possibilit√© de joindre avec un crit√®re < ou >. Ce n'est pas possible avec les algorithmes pr√©c√©dents. \
Attention : Il s'agit de la strat√©gie la moins rapide, m√™me dans un cas d'√©galit√©. Elle fait une comparaison totale dans tous les cas afin de supporter des crit√®res de jointures particuliers.

5 - Cartesian Product Join : Il s'agit de la jointure na√Øve. Elle est presque syst√©matiquement √† √©viter. Elle r√©sulte souvent dans des erreurs m√©moires, m√™me avec des tables de taille moyenne. &#x20;

Spark choisit lui m√™me une strat√©gie 'adapt√©e' en fonction de param√®tres par d√©fauts, mais on peut forcer la strat√©gie pour gagner du temps si celle choisie ne nous correspond pas √† ce que l'on souhaite faire.

#### Le [repartitionnement d'une table](https://spark.apache.org/docs/3.1.3/api/python/reference/api/pyspark.sql.DataFrame.repartition.html) si celle-ci est mal partitionn√©e

Dans l'exemple cit√© en √©tape 1 : on pourrait envisager de repartionner la table avec un nombre de partitions inf√©rieures, afin de profiter de plus de data locality, et avoir un shuffling moins important

En r√®gle g√©n√©rale, le nombre de partition d'une table doit √™tre contenue entre :&#x20;

Au minimum : 2 x le nombre de c≈ìurs choisis pour l‚Äôapplication

Au maximum : au moins 100ms de temps d'ex√©cution par partition, au dela, c'est que la table est trop partitionn√©e, et donc on perds du temps lors des op√©rations qui n√©c√©ssitent un shuffling.

#### L'adaptation des ressources ([En R](8\_spark\_usage.md#configurer-spark-en-mode-local) / [En Python](utiliser-spark-avec-python.md#configurer-spark-en-mode-local)) allou√©es au traitement

Dans certains cas, les donn√©es d√©passent la taille de la m√©moire allou√©e au traitement. S'il est posssible de le faire, on peut envisager l'augmentation de la m√©moire pour que l'ensemble des donn√©es soient charg√©es en m√©moire. Sinon, cela provoque la mont√©e et descente intempestive de donn√©es entre disque et m√©moire pour que les donn√©es puissent √™tre lues par Spark. Ce n'est pas optimal.

#### Eviter d'utiliser un collect&#x20;

L'instruction collect sur une trop grande quantit√© de donn√©es provoque de grands d√©placements de donn√©es. Ce n'est pas souvent efficace. Par cons√©quent, si on souhaite vraiment visualiser le r√©sultat, il est pr√©f√©rable d'afficher les 5 premi√®res lignes de la table, ce qui est nettement moins consommateur de ressources et de temps.

#### Utiliser un cache ou [HDFS](../gestion-des-clusters/gestion-des-donnees-avec-hdfs.md) pour stocker un r√©sultat interm√©diaire

Pour √©viter le recalcul de certains r√©sultats, utiliser un cache ou stocker le r√©sultat est une option envisageable lorsque beaucoup de calculs sont effectu√©s. Attention cependant √† l'abus d'utilisation du cache : cette op√©ration ne doit √™tre utilis√©e que dans un objectif d'optimisation, pas de fa√ßon syst√©matique apr√®s chaque calcul, sous peine de consommer l'ensemble de la m√©moire sans gain de vitesse. En particulier, il ne faut pas mettre en cache un jeu de donn√©es qui ne tient pas en m√©moire.

### √âtape 3 : Comparer avec ou sans l'optimisation

Une fois votre strat√©gie d'optimisation d√©finie, vous pouvez effectuer un benchmark pour comparer si la strat√©gie d'optimisation a permis de r√©duire le temps de calcul. En utilisant le Spark UI, vous pouvez obtenir la dur√©e de traitement ou alors d√©finir dans votre code des balises de temps pour mesurer la dur√©e d'une fonction :&#x20;

En pyspark :

```python
from pyspark.sql import SparkSession
import time

def my_spark_function():
    spark = SparkSession.builder.appName("mon_application").getOrCreate()
    
    # Transformations
    df = spark.read.csv("chemin/vers/votre/fichier.csv", header=True, inferSchema=True)
    result_df = df.groupBy("colonne").count()
    
    # Action
    result_df.show()

start_time = time.time()
my_spark_function()
end_time = time.time()
duration = end_time - start_time

# Affichez la dur√©e
print(f"La fonction Spark a mis {duration} secondes pour s'ex√©cuter.")
```

En SparklyR :&#x20;

```r
library(sparklyr)
library(dplyr)
library(SparkR)
library(SparkR::sparklyr)

my_spark_function <- function() {
  spark <- spark_connect(master = "local", version = "3.0.2")
  
  # Traitement
  df <- spark_read_csv(spark, "chemin/vers/votre/fichier.csv", header = TRUE, infer_schema = TRUE)
  result_df <- df %>% group_by(colonne) %>% summarize(count = n())

  # Action
  spark_print(result_df)
}

start_time <- Sys.time()
my_spark_function()
end_time <- Sys.time()

duration <- end_time - start_time

cat(paste("La fonction Spark a mis", as.numeric(duration), "secondes pour s'ex√©cuter.\n"))
```
