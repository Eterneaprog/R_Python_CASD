# üë©üè´ Comprendre les traitements avec Spark

## Qu'est-ce que Spark ?

Spark est un moteur de calcul multi-langage, orient√© pour traiter des grands volumes de donn√©es, sur une machine locale, ou sur plusieurs machines formant un cluster.

Il permet d'effectuer toutes sortes de t√¢ches :&#x20;

* De la gestion de donn√©es avec SQL
* Du traitement de donn√©es en streaming - au fur et √† mesure que celles-ci arrivent -
* Du machine learning avec la librairie MLlib
* Des graphs avec GraphX

Il peut √™tre utilis√© avec une syntaxe proche de Python : c'est PySpark, et avec une syntaxe proche de R,  c'est SparkR ou sparklyR (pour les amateurs de deeplyr en particulier).

## Pourquoi utiliser Spark ?

Spark offre un niveau de performance tr√®s √©lev√© : il est capable d'effectuer de multiples t√¢ches en m√™me temps, tout en faisant une utilisation optimale de la m√©moire. C'est un moteur nativement pens√© pour la haute performance.&#x20;

De plus, s'il devient n√©cessaire de faire fonctionner le code sur un cluster, pour traiter de tr√®s grands volumes, le code Spark √©crit pour une machine local est identique. Il suffit de modifier la configuration afin de faire fonctionner le programme sur un cluster plut√¥t que sur sa machine locale.

Enfin, Spark est disponible avec de multiples syntaxes, pour favoriser son accessibilit√©.&#x20;

## Mode local contre mode distribu√©

Spark est un logiciel capable d'effectuer des t√¢ches de fa√ßon parall√®les. C'est-√†-dire : effectuer plusieurs morceaux de calculs en m√™me temps, puis rassembler les r√©sultats obtenus en un seul morceau. \
Par exemple : si on souhaite appliquer un traitement √† chaque ligne d'une table contenant un grand nombre d'observations : il est int√©ressant d'utiliser cette technique, car on va diviser le temps total de l'op√©ration par le nombre de t√¢ches que l'on peut effectuer de mani√®re parall√®le.&#x20;

Le mode local est le fait d'utiliser Spark sur sa propre machine. Il n'y a donc qu'une machine (virtuelle ici) qui travaille, c'est votre bulle. Spark utilise les capacit√©s de cette machine pour lui faire effectuer des t√¢ches de mani√®re parall√®le. Ce mode permet d'effectuer des gains algorithmiques. En effet, si la machine poss√®de plusieurs c≈ìurs, on peut effectuer plusieurs t√¢ches √† la fois plut√¥t que de les faire les unes √† la suite des autres.

Le mode cluster est le fait d'utiliser un parc de machines distantes sur lequel Spark est install√©. On se connecte alors au n≈ìud principal (c'est le master), et on donne des instructions √† ce master qui fait travailler des workers. En pratique, cela veut dire faire ex√©cuter les diff√©rents morceaux du traitement sur plusieurs machines distinctes, plut√¥t que sur la m√™me. Cela poss√®de l'int√©r√™t de cumuler les puissances de calculs de plusieurs machines. Cependant, cela g√©n√®re aussi un trafic r√©seau important, car il faut faire communiquer les machines. Cette organisation des machines est nomm√©e cluster. La maintenir et la d√©ployer est en g√©n√©ral √† la charge de votre fournisseur d'acc√®s. Cependant, [comprendre le fonctionnement d'un cluster](../clusters/) permet de l'utiliser de fa√ßon optimis√©e. Le CASD propose un service de mise √† disposition d'un cluster de calcul privatif pour les projets le n√©cessitant. Ce cluster n'est pas partag√© avec d'autres bulles afin d'assurer une totale isolation, comme sur une bulle classique.

## Les ressources avec Spark

Spark utilise massivement [la m√©moire ](../performance-calculs/ressources.md#la-memoire)pour acc√©l√©rer de mani√®re drastique vos calculs. Il s'agit du gain principal de cette technologie par rapport aux plus anciennes comme Hadoop. En effet, en chargeant les donn√©es dans la m√©moire, cela permet de les lire plusieurs fois de mani√®re quasi instantan√©e. Cependant, il faut √™tre attentif √† la consommation m√©moire et ne pas charger √† plusieurs reprises les m√™mes donn√©es. Il s'agit du m√™me probl√®me qu'en R. Cela peut cr√©er des saturations m√©moires et consommer √©norm√©ment de places pour des r√©sultats peu probants.

Pour cette raison, il est tr√®s important de bien d√©terminer les ressources que vous souhaitez allouer √† votre session. Une fois allou√©e, et tant que cette session ne sera pas achev√©e, elles seront r√©serv√©es. Ind√©pendamment du mode choisi, une bonne gestion ressources est essentielle pour le travail collaboratif.
