---
layout:
  title:
    visible: true
  description:
    visible: true
  tableOfContents:
    visible: true
  outline:
    visible: true
  pagination:
    visible: false
---

# üöß Installer et param√©trer Spark

## Principes g√©n√©raux

> _Qu'est ce qu'un cluster ? Quelle diff√©rence avec Spark ?_
>
> Un cluster est un regroupement de machines de travail (les workers), sous la direction d'une machine ma√Ætre (le master). Le master se charge de distribuer le travail sur les diff√©rents machines de travail et de collecter les r√©sultats. Cela permet de travailler de fa√ßon parall√®le, et donc de gagner du temps. Spark est un logiciel avec lequel vous allez √©changer pour faire fonctionner un cluster. Vous pouvez √©crire vos instructions dans une syntaxe plus proche du R : c'est SparkR, ou bien avec une syntaxe proche du Python : c'est PySpark ! Il est √† noter que l'on peut tout √† fait utiliser Spark sans cluster, c'est le mode local. De m√™me, on peut interagir avec un cluster avec d'autres logicielles que Spark.

Voici un aper√ßu simplifi√© du fonctionnement d'un cluster Spark :

<figure><img src="../chapters/images/spark.png" alt=""><figcaption><p>Un exemple de cluster Spark</p></figcaption></figure>

Un cluster Spark est un outil puissant qui permet d'acc√©l√©rer grandement la vitesse d'ex√©cution de vos calculs. De plus, la puissance du cluster et sa taille sont plus modulables qu'une machine seule √† laquelle on ajoute des ressources : il suffit d'ajouter des workers. Cependant, l'utilisation de cet outil n'est pas toujours aussi ais√©e que lorsque l'on s'adresse une machine seule avec R. Voyons d'abord comment installer les paquets n√©cessaires pour pouvoir s'adresser √† Spark en R, puis en python. Ensuite, nous verrons comment r√©server des ressources (il s'agit de la notion de Spark Context sur le sch√©ma, aussi appel√©e SparkSession aujourd'hui). Cela nous permettra de simuler un cluster en ex√©cutant nos codes localement avec Spark. Les personnes poss√©dant un acc√®s √† un cluster apprendrons ensuite √† modifier l'instruction SparkSession, afin de passer du mode local au mode cluster. Enfin, nous verrons comment utiliser notre cluster pour effectuer des calculs simples.

## Effectuer les installations n√©cessaires

### Installer Spark

Pour simplifier l'installation de Spark, nous avons con√ßu un script qui effectue cette installation de fa√ßon automatis√©e. Il est situ√© dans l'espace commun. Que vous souhaitiez adresser le logiciel Spark avec une syntaxe proche de R ou de Python, cette √©tape est n√©cessaire.

Cliquez sur AutoInstallSpark.bat afin d'effectuer l'installation.

**Attention :** Vous devez attendre la fin du script et qu'il demande d'appuyer sur entr√©e pour terminer. Il ne faut pas fermer la fen√™tre du terminal ouvert pendant le script, cette op√©ration n'est pas tr√®s longue.

Ce script d√©compresse l'archive contenant Spark, copie les fichiers n√©cessaires √† son utilisation sous Windows, et param√®tres les variables d'environnement.

Vous pouvez tester l'installation avec la commande suivante dans un terminal de commande (cmd)¬†:

```bash
spark-shell
```

### Installer le package SparklyR pour travailler avec SparkR dans Rstudio

Si vous souhaitez utiliser SparkR pour soumettre vos instructions au cluster, vous aurez besoin de la librairie SparklyR. Voici la marche √† suivre une fois que l'installation de Spark a √©t√© effectu√©e :

Proc√©dez d'abord √† l'installation du package SparklyR √† l'aide du d√©p√¥t, comme dans les chapitres pr√©c√©dents, puis chargez-le¬†:

```r
install.packages("sparklyr")
library("sparklyr")
```

Ensuite, connectez-vous au cluster :

```r
sc <- spark_connect(master="local")
```

Vous poss√©dez un serveur Spark adressable avec R pour votre application‚ÄØ!

### Installer PySpark et adresser le cluster avec un Notebook Jupyter

PySpark est inclus nativement avec Spark. Une fois l'installation de Spark effectu√©e avec le script fourni, vous pouvez acc√©der √† pyspark dans votre application avec la commande :

```bash
pyspark
```

### Installer les autres d√©pendances de Spark

Les fichiers Jar additionnels dont vous pouvez avoir besoin pour installer des librairies Spark peuvent √™tre obtenus dans le m√™me dossier que pour l'installation de SparklyR : dans S:\Spark\jar\_files. Vous trouverez ici les binaires √† copier, par exemple, celui qui permet d'ouvrir un fichier SAS avec Spark : spark-sas7bdat, dans diff√©rentes versions. De m√™me, vous pourrez installer parso avec la man≈ìuvre qui suit :

* Copiez le Jar de votre choix dans le dossier : "C:\Users\projet\_0\_p\_nom0000\AppData\Local\spark\spark-3.3.2-bin-hadoop2\jars"

## R√©server des ressources avec l'instruction SparkSession pour le mode local

> _Mode local ? Mode cluster ?_
>
> Le mode local est le fait d'utiliser Spark sur sa machine actuelle. Il n'y a donc qu'une machine qui travaille, ici, c'est votre bulle. Spark utilise les capacit√©s de cette machine pour lui faire effectuer des t√¢ches de fa√ßon parall√®le. Il reste donc int√©ressant d'utiliser ce mode, car des gains algorithmiques sont effectu√©s. Il n'y a cependant pas vraiment de workers comme dans le sch√©ma initial pr√©sent√©, ils sont fictifs, puisqu'il n'y a qu'une machine. Le mode cluster est le fait d'utiliser un parc de machine distant sur lequel Spark est install√©. On se connecte alors au noeud principal (c'est le master), et on donne des instruction √† ce master qui fait travailler des workers. C'est le sch√©ma initialement pr√©sent√©. Si votre projet dispose d'un cluster, il vous est possible de l'utiliser, afin d'acc√©l√©rer vos calculs, avec plus de ressources qu'en mode local.

Spark utilise massivement la m√©moire afin d'acc√©l√©rer de fa√ßon drastique vos calculs. Pour cette raison, il est tr√®s important de bien d√©terminer les ressources que vous souhaitez allouer √† votre session. Une fois allou√©e, et tant que cette session ne sera pas achev√©e, elles seront r√©serv√©es.

> _Comment les ressources sont elles partag√©es entre les utilisateurs du cluster ?_
>
> Attention: dans un cluster spark les ressources sont partag√©es et vous devez en r√©server une partie de fa√ßon pr√©alable pour effectuer un traitement. C'est ce que nous allons apprendre √† faire dans cette section, en python et en R. Il est fondamental de lib√©rer les ressources apr√®s utilisation en fermant votre session spark avec l'instruction spark.close() ! Autrement, vos ressources restent allou√©es, m√™me apr√®s la fin de votre traitement. De m√™me, il convient d'√™tre raisonnable en choisissant une allocation m√©moire et processeur adapt√©e √† votre traitement afin de laisser des ressources aux autres utilisateurs du cluster.

### En PySpark :

```python
from pyspark.sql import SparkSession

# Configuration des ressources
spark = SparkSession.builder \
    .appName("ExempleJointureSimple") \  # Nom de l'application Spark
    .config("spark.executor.memory", "8g") \  # M√©moire allou√©e par ex√©cuteur
    .config("spark.executor.cores", 4) \  # Coeurs par ex√©cuteur
    .config("spark.driver.memory", "4g") \  # M√©moire allou√©e au driver (processus principal)
    .config("spark.driver.cores", 2) \  # Coeurs allou√©s au driver
    .getOrCreate()
```

Voi√ßi un exemple simple de configuration Spark. Les ressources doivent √™tre proportionnelles √† la t√¢che effectu√©e et aux donn√©es trait√©es par votre application.

### Avec SparklyR :

```r
library(sparklyr)

# Configuration des ressources
config <- spark_config()

config$spark.executor.memory <- "8g" # M√©moire allou√©e par ex√©cuteur
config$spark.executor.cores <- 4 # Coeurs par ex√©cuteur
config$spark.driver.memory <- "4g" # M√©moire allou√©e au driver
config$spark.driver.cores <- 2 # Coeurs allou√©s au driver

# Cr√©ation de la connexion Sparklyr
sc <- spark_connect(master = "local", config = config, version = "3.3.2")
```

## Passer en mode cluster

Si vous acc√®s √† un cluster dans votre projet, vous pouvez quitter le mode local et passer en mode cluster afin de disposer d'une plus grande quantit√© de ressources.

Pour cela, rien de plus simple, il suffit de r√©utiliser les configurations du mode local, en mettant √† jour les valeurs param√®tres vers des valeurs plus adapt√©es √† la puissance de calcul de votre cluster.

Il suffit ensuite de modifier l'instuction de connexion :

En SparklyR :

```r
# URL du cluster Spark
cluster_url <- "spark://adresse_du_cluster:port"

# Cr√©ation de la connexion Sparklyr en mode cluster
sc <- spark_connect(master = cluster_url, config = config, version = "2.4.7")
```

En PySpark :

```
from pyspark.sql import SparkSession

# Configuration des ressources pour le cluster
spark = SparkSession.builder \
    .appName("MonApplication") \  # Nom de l'application Spark
    .config("spark.executor.memory", "8g") \  # M√©moire allou√©e par ex√©cuteur
    .config("spark.executor.cores", 4) \  # Coeurs par ex√©cuteur
    .config("spark.driver.memory", "4g") \  # M√©moire allou√©e au driver
    .config("spark.driver.cores", 2) \  # Coeurs allou√©s au driver
    .config("spark.master", "spark://adresse_du_cluster:port") \  # URL du gestionnaire de cluster Spark
    .getOrCreate()
```
